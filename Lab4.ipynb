{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b20bc641-3b73-4cef-a625-9ab7593933af",
   "metadata": {
    "id": "b20bc641-3b73-4cef-a625-9ab7593933af"
   },
   "source": [
    "# Zadanie 4 - Architektura wielowarstwowych sieci neuronowych\n",
    "Miłosz Sadziński 259139\n",
    "\n",
    "Celem ćwiczenia jest zapoznanie się z architekturą wielowarstwowych sieci perceptronowych. W tym celu wykorzystano zbiór danych otrzymanych w poprzednim ćwiczeniu i uruchomiono skrypt w usłudze Google Colabolatory. Wynik działania skryptu znajduje się w tym notatniku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86a9f0ec-5e02-4d43-be12-451562d7f771",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86a9f0ec-5e02-4d43-be12-451562d7f771",
    "outputId": "329e966b-42e4-4384-9eb1-08a111ce1902"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.0612 - loss: 2.9985\n",
      "Epoch 2/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1012 - loss: 2.8319\n",
      "Epoch 3/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1020 - loss: 2.7497\n",
      "Epoch 4/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1096 - loss: 2.6591\n",
      "Epoch 5/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.1259 - loss: 2.5789\n",
      "Epoch 6/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1229 - loss: 2.5890\n",
      "Epoch 7/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1419 - loss: 2.4995\n",
      "Epoch 8/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1489 - loss: 2.4456\n",
      "Epoch 9/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2053 - loss: 2.4096\n",
      "Epoch 10/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2276 - loss: 2.3505\n",
      "Epoch 11/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2251 - loss: 2.2881\n",
      "Epoch 12/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2402 - loss: 2.2294\n",
      "Epoch 13/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2383 - loss: 2.1993\n",
      "Epoch 14/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2493 - loss: 2.1602\n",
      "Epoch 15/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2349 - loss: 2.1741\n",
      "Epoch 16/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1784 - loss: 2.2411\n",
      "Epoch 17/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2501 - loss: 2.0832\n",
      "Epoch 18/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2465 - loss: 2.0623\n",
      "Epoch 19/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2516 - loss: 2.0236\n",
      "Epoch 20/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2479 - loss: 2.0120\n",
      "Epoch 21/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2420 - loss: 1.9988\n",
      "Epoch 22/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2522 - loss: 1.9655\n",
      "Epoch 23/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2448 - loss: 1.9774\n",
      "Epoch 24/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2515 - loss: 1.9417\n",
      "Epoch 25/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2559 - loss: 1.9403\n",
      "Epoch 26/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2585 - loss: 1.9199\n",
      "Epoch 27/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2460 - loss: 1.9071\n",
      "Epoch 28/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2627 - loss: 1.8941\n",
      "Epoch 29/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2436 - loss: 1.8976\n",
      "Epoch 30/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2676 - loss: 1.8591\n",
      "Epoch 31/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2380 - loss: 1.8823\n",
      "Epoch 32/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2714 - loss: 1.8523\n",
      "Epoch 33/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2689 - loss: 1.8777\n",
      "Epoch 34/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2756 - loss: 1.8816\n",
      "Epoch 35/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2806 - loss: 1.8450\n",
      "Epoch 36/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2755 - loss: 1.8505\n",
      "Epoch 37/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3052 - loss: 1.8278\n",
      "Epoch 38/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2838 - loss: 1.8835\n",
      "Epoch 39/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3070 - loss: 1.8265\n",
      "Epoch 40/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3017 - loss: 1.8133\n",
      "Epoch 41/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3088 - loss: 1.7849\n",
      "Epoch 42/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3138 - loss: 1.7936\n",
      "Epoch 43/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3065 - loss: 1.7885\n",
      "Epoch 44/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3175 - loss: 1.7754\n",
      "Epoch 45/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2588 - loss: 1.9559\n",
      "Epoch 46/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2486 - loss: 1.9833\n",
      "Epoch 47/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2624 - loss: 1.9464\n",
      "Epoch 48/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2512 - loss: 2.0102\n",
      "Epoch 49/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2420 - loss: 1.9725\n",
      "Epoch 50/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2474 - loss: 1.9443\n",
      "Epoch 51/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2515 - loss: 1.9924\n",
      "Epoch 52/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1607 - loss: 2.3535\n",
      "Epoch 53/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1684 - loss: 2.2839\n",
      "Epoch 54/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1667 - loss: 2.2747\n",
      "Epoch 55/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1750 - loss: 2.2645\n",
      "Epoch 56/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1227 - loss: 2.5174\n",
      "Epoch 57/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1055 - loss: 2.4842\n",
      "Epoch 58/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1152 - loss: 2.4740\n",
      "Epoch 59/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1129 - loss: 2.4548\n",
      "Epoch 60/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1753 - loss: 2.2726\n",
      "Epoch 61/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1651 - loss: 2.2331\n",
      "Epoch 62/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1639 - loss: 2.2319\n",
      "Epoch 63/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1757 - loss: 2.2210\n",
      "Epoch 64/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1781 - loss: 2.2316\n",
      "Epoch 65/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1755 - loss: 2.2153\n",
      "Epoch 66/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1629 - loss: 2.2304\n",
      "Epoch 67/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1680 - loss: 2.2231\n",
      "Epoch 68/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1655 - loss: 2.2267\n",
      "Epoch 69/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1685 - loss: 2.2133\n",
      "Epoch 70/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1759 - loss: 2.2304\n",
      "Epoch 71/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1704 - loss: 2.2101\n",
      "Epoch 72/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1717 - loss: 2.2114\n",
      "Epoch 73/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1740 - loss: 2.2121\n",
      "Epoch 74/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1717 - loss: 2.1861\n",
      "Epoch 75/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1657 - loss: 2.2085\n",
      "Epoch 76/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1688 - loss: 2.1951\n",
      "Epoch 77/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1818 - loss: 2.2025\n",
      "Epoch 78/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1773 - loss: 2.1872\n",
      "Epoch 79/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1707 - loss: 2.1855\n",
      "Epoch 80/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1637 - loss: 2.1857\n",
      "Epoch 81/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1739 - loss: 2.2004\n",
      "Epoch 82/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1771 - loss: 2.1845\n",
      "Epoch 83/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1871 - loss: 2.1660\n",
      "Epoch 84/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2509 - loss: 2.0547\n",
      "Epoch 85/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2556 - loss: 2.0208\n",
      "Epoch 86/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2483 - loss: 1.9220\n",
      "Epoch 87/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2432 - loss: 2.0252\n",
      "Epoch 88/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2611 - loss: 1.9419\n",
      "Epoch 89/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2511 - loss: 1.9223\n",
      "Epoch 90/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2594 - loss: 1.8846\n",
      "Epoch 91/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2702 - loss: 1.9002\n",
      "Epoch 92/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2888 - loss: 1.8097\n",
      "Epoch 93/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2706 - loss: 1.8106\n",
      "Epoch 94/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2999 - loss: 1.7641\n",
      "Epoch 95/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2995 - loss: 1.7398\n",
      "Epoch 96/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2750 - loss: 1.7391\n",
      "Epoch 97/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2808 - loss: 1.7552\n",
      "Epoch 98/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2752 - loss: 1.7653\n",
      "Epoch 99/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2716 - loss: 1.7564\n",
      "Epoch 100/100\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2757 - loss: 1.7461\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "[[  1   2   3 116   0   0   0   0   0   0   0   0   0   0   0   0   1  18]\n",
      " [  1   2   3  92   2   0   0   0   0   0   0   0   0   0   0   0   1  53]\n",
      " [  0   2   6 120   5   0   0   0   0   0   0   0   0   0   0   0   0   8]\n",
      " [  1   1   0 133   1   0   0   0   0   0   0   0   0   0   0   0   0   4]\n",
      " [  0   0   0   5 129   0   0   0   0   0   0   0   0   3   0   0   0   0]\n",
      " [  0   0   1   2 158   0   0   0   0   0   0   1   0   1   0   0   0   0]\n",
      " [  0   0   0   3 146   0   0   0   0   0   0   1   0   0   0   0   0   0]\n",
      " [  0   0   1   2   3   0   0 154   0   0   0   0   0   2   0   0   0   0]\n",
      " [  0   0   0   7   5   0   0 121   3   3   0   0   0  16   0   0   0   1]\n",
      " [  0   0   0   3   4   0   0 156   2   1   0   1   0   2   0   0   0   0]\n",
      " [  0   0   0   3   5   0   0 138   1   2   0   0   0   7   0   0   1   1]\n",
      " [  0   0   0   2  97   0   0   0   0   0   0   5   1  43   0   0   0   0]\n",
      " [  0   0   0   4  28   0   0   0   0   0   0   5   4  91   0   0  13   1]\n",
      " [  0   0   0   2  40   0   0   0   0   0   0   5   5 105   0   0   3   0]\n",
      " [  0   0   2   4  53   0   0   0   0   0   0   2   6  99   0   0  10   0]\n",
      " [  0   0   0  17   5   0   0   0   0   1   0   0   0   0   0   0  21 119]\n",
      " [  0   0   0   7   1   0   0   0   0   0   0   0   3   3   0   0  56  76]\n",
      " [  1   3   0  12   0   0   0   0   0   0   0   0   0   1   0   0   9 129]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.api.layers import Dense, Input\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "features = pd.read_csv('wektory_512.csv', sep=',') # Dane wejściowe\n",
    "data = np.array(features) # Konwersja na tablicę numpy\n",
    "X = (data[:,:-1]).astype('float64') # Wyodrębnianie wektora cech do macierzy X\n",
    "Y = data[:,-1] # Wyodrębnianie etykiety kategorii do wektora Y\n",
    "\n",
    "# Kodowanie etykiet klas jako liczby całkowite\n",
    "label_encoder = LabelEncoder()\n",
    "y_int = label_encoder.fit_transform(Y)\n",
    "\n",
    "# Kodowanie etykiet klas One-hot\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "y_onehot = onehot_encoder.fit_transform(y_int.reshape(-1, 1))\n",
    "\n",
    "# Podział danych na zbiór treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.3)\n",
    "\n",
    "# Tworzenie modelu sieci neuronowej\n",
    "n_classes = y_train.shape[1]\n",
    "model = Sequential()\n",
    "input_dim = X.shape[1]  # Dynamicznie wyznanacza liczba kolumn w zbiorze cech\n",
    "model.add(Input(shape=(input_dim,)))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# Uczenie sieci\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=10, shuffle=True)\n",
    "\n",
    "# Testowanie sieci\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687d294a-1242-4ffa-94cc-5d5b9447b13b",
   "metadata": {
    "id": "e6e94c69-7ccb-4148-95e4-256230a3a302"
   },
   "source": [
    "W wyniku działania skryptu otrzymaliśmy macierz pomyłek zawierającą informacje o tym ile próbek zostało sklasyfikowanych jako poszczególna klasa. Wartości tutaj otrzymane są liczbami całkowitymi, co stanowi różnicę w porównaniu do macierzy z poprzedniego zadania, w którym wartości w komórkach przyjmowały wartości od 0 do 1. Otrzymane wyniki odpowiadają temu co było badane tj. zdjęć klasy drzwi były 4 szt, paneli 3 szt, płytek 4 szt, tynku 4 szt i ściany 3 szt. Niestety jednak algorytm nie dał rady zidentyfikować dokładnie próbek, widać jednak pewne zależności na próby poprawnej identyfikacji. Widać też dużą anomalię w piątej kolumnie wiersz 12-15, gdzie próbki tynku zostały błędnie zidentyfikowane jako panele. Oba podejścia do badania dają podobne rezultaty, jednakże wyniki z poprzedniego zadania wydają się być dokładniejsze, prawdopodobnie jest to związane z ilością bardzo podobnych do siebie zdjęc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86861a60-5a50-46a0-8e0d-d58b6f642b54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
